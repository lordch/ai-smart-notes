# Źródła: AI Slop w pracy intelektualnej
## Annotowana bibliografia z metadanymi

---

## Legenda oceny autorytatywności

| Ocena | Znaczenie |
|-------|-----------|
| ⭐⭐⭐⭐⭐ | Peer-reviewed journal, top-tier institution |
| ⭐⭐⭐⭐ | Reputable research institution, quality journalism |
| ⭐⭐⭐ | Expert blog/newsletter, industry analysis |
| ⭐⭐ | Secondary reporting, aggregator |
| ⭐ | Anecdotal, limited verification |

---

## 1. FUNDAMENTALNE BADANIA NAUKOWE

### Mathematical Ceiling on AI Creativity
- **Tytuł:** A mathematical ceiling limits generative AI to amateur-level creativity
- **Autor:** David Cropley (University of South Australia)
- **Publikacja:** *Journal of Creative Behavior* (Wiley)
- **Data:** 2025
- **Typ:** Peer-reviewed paper
- **Link:** https://www.psypost.org/a-mathematical-ceiling-limits-generative-ai-to-amateur-level-creativity/
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **KLUCZOWE** - Formalizuje matematycznie dlaczego LLM-y mają ceiling na kreatywność (0.25 na skali 0-1). Dostarcza teoretyczną podstawę dla argumentu o strukturalnych ograniczeniach AI w pracy intelektualnej. Wyjaśnia trade-off novelty vs. effectiveness.

---

### On Limitations of the Transformer Architecture
- **Autorzy:** Binghui Peng, Arvind Narayanan, Christos Papadimitriou
- **Publikacja:** arXiv (preprint)
- **Data:** Luty 2024
- **Typ:** Technical paper / preprint
- **Link:** https://arxiv.org/html/2402.08164v1
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **KLUCZOWE** - Matematyczny dowód, że architektura Transformer jest "fundamentalnie niekompatybilna" z pewnymi zadaniami rozumowania (np. function composition). Wyjaśnia dlaczego AI zawodzi przy łączeniu dwóch faktów w jeden wniosek.

---

### LLM Cannot Discover Causality
- **Autorzy:** Weizhuo Li, Jiayuan Sun, Mingze Wang et al.
- **Publikacja:** arXiv
- **Data:** Czerwiec 2025
- **Typ:** Peer-reviewed preprint
- **Link:** https://arxiv.org/abs/2506.00844
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Dowodzi, że autoregresyjne modelowanie LLM "inherently lacks the theoretical grounding for causal reasoning". Rekomenduje ograniczenie LLM do roli non-decisional support. Fundamentalne dla argumentu o ograniczeniach w insight generation.

---

### The Illusion of Thinking (Apple Research)
- **Autorzy:** Apple Machine Learning Research Team
- **Publikacja:** Apple ML Research
- **Data:** 2025
- **Typ:** Corporate research paper
- **Link:** https://machinelearning.apple.com/research/illusion-of-thinking
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Pokazuje, że Large Reasoning Models doświadczają "complete accuracy collapse" przy wysokiej złożoności i paradoksalnie *redukują* wysiłek rozumowania gdy problemy stają się trudniejsze. Podważa narrację o "reasoning models" jako rozwiązaniu ograniczeń.

---

### AI Tools in Society: Impacts on Cognitive Offloading
- **Autorzy:** Badacze SBS Swiss Business School
- **Publikacja:** MDPI *Societies* (peer-reviewed, open access)
- **Data:** Styczeń 2025
- **Typ:** Peer-reviewed empirical study
- **Link:** https://www.mdpi.com/2075-4698/15/1/6
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **KLUCZOWE** - Największe badanie empiryczne (n=666) korelacji między użyciem AI a critical thinking. Korelacja r=-0.68 między AI usage a critical thinking scores. Kluczowe dane ilościowe dla sekcji o wpływie na myślenie.

---

### The Impact of Generative AI on Critical Thinking (Microsoft Research)
- **Autorzy:** Microsoft Research + Carnegie Mellon University
- **Publikacja:** Microsoft Research
- **Data:** Luty 2025
- **Typ:** Corporate/academic research
- **Link:** https://www.microsoft.com/en-us/research/publication/the-impact-of-generative-ai-on-critical-thinking-self-reported-reductions-in-cognitive-effort-and-confidence-effects-from-a-survey-of-knowledge-workers/
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - 319 knowledge workers, 936 real-world use cases. Pokazuje inverse correlation między confidence in AI a critical thinking. Definiuje shift "from problem-solving to AI response integration".

---

### Homogenizing Effect of LLMs on Creative Diversity
- **Publikacja:** ScienceDirect (Elsevier)
- **Data:** 2025
- **Typ:** Peer-reviewed empirical study
- **Link:** https://www.sciencedirect.com/science/article/pii/S294988212500091X
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Empiryczne porównanie human vs ChatGPT writing pokazujące homogenizację. Kluczowe dla sekcji o utracie różnorodności perspektyw.

---

### Homogenization Effects of LLMs on Human Creative Ideation
- **Autorzy:** Max Kreminski et al. (Georgetown/Stanford)
- **Publikacja:** C&C 2024 (Creativity and Cognition Conference)
- **Data:** 2024
- **Typ:** Peer-reviewed conference paper
- **Link:** https://mkremins.github.io/publications/Homogenization_C&C2024.pdf
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Analiza 2,200+ college admission essays. Pokazuje, że homogenizacja wynika z group-level suggestion podobnych idei różnym użytkownikom, nie z individual fixation. Prompt modifications nie mitigują diversity gap.

---

### Creative Scar Without Generative AI
- **Publikacja:** ScienceDirect / Technology in Society
- **Data:** 2025
- **Typ:** Peer-reviewed longitudinal study
- **Link:** https://www.sciencedirect.com/science/article/abs/pii/S0160791X25002775
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Longitudinalnie (61 studentów) pokazuje, że homogeneity "keeps climbing even months later" - efekt "creative scar". Kluczowe dla argumentu o trwałych skutkach.

---

### AI on Trial: Legal Models Hallucinate (Stanford HAI)
- **Autorzy:** Stanford Human-Centered AI Institute
- **Publikacja:** Stanford HAI
- **Data:** 2024
- **Typ:** Research report
- **Link:** https://hai.stanford.edu/news/ai-trial-legal-models-hallucinate-1-out-6-or-more-benchmarking-queries
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Benchmark pokazujący hallucination rates: Lexis+ AI 17%+, Westlaw AI 34%+, general chatbots 58-82%. Kluczowe dane dla domain-specific failures w prawie.

---

### Fabrication and Errors in Bibliographic Citations (Nature)
- **Publikacja:** *Scientific Reports* (Nature)
- **Data:** 2023
- **Typ:** Peer-reviewed study
- **Link:** https://www.nature.com/articles/s41598-023-41032-5
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Foundational study on citation fabrication. 55% GPT-3.5 citations fabricated, 18% for GPT-4. 64% fabricated DOIs link to real but unrelated papers.

---

### RLHF User Values Research (University of Washington)
- **Autorzy:** UW Researchers
- **Publikacja:** University of Washington News
- **Data:** Grudzień 2024
- **Typ:** University research
- **Link:** https://www.washington.edu/news/2024/12/18/ai-user-values-preferences-rlhf/
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE-WYSOKIE** - Wyjaśnia mechanizm RLHF jako averaging: "the model can basically try to average all preferences together, and this can be incorrect for all users". Klucz dla zrozumienia dlaczego AI produkuje "bezpieczne" odpowiedzi.

---

### The Extended Hollowed Mind (PMC/NIH)
- **Publikacja:** PubMed Central
- **Data:** 2025
- **Typ:** Peer-reviewed paper
- **Link:** https://pmc.ncbi.nlm.nih.gov/articles/PMC12738859/
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Filozoficzny argument za koniecznością foundational knowledge w erze AI. Uzupełnia empiryczne badania perspektywą teoretyczną.

---

### Can AI Writing Be Salvaged? (arXiv)
- **Publikacja:** arXiv
- **Data:** Wrzesień 2024
- **Typ:** Preprint
- **Link:** https://arxiv.org/html/2409.14509v1
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Analiza idiosyncrasies w AI writing i możliwości mitigation przez edycję. Pokazuje, że problemy są rozpoznawalne i częściowo naprawialne.

---

## 2. EKSPERCI DOMENOWI I BLOGI TECHNICZNE

### The Deep Research Problem - Benedict Evans
- **Autor:** Benedict Evans (tech analyst, były a16z)
- **Publikacja:** benedictevans.com
- **Data:** Luty 2025
- **Typ:** Expert blog
- **Link:** https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **KLUCZOWE** - Testuje Deep Research na własnej domenie ekspertyzy (smartphone data). Pokazuje konkretne błędy: SEO aggregators jako źródła, błędy faktyczne z własnych cytowanych źródeł. Fundamentalne dla krytyki deep research tools.

---

### How I Use LLMs to Help Me Write Code - Simon Willison
- **Autor:** Simon Willison (creator of Datasette, Django co-creator)
- **Publikacja:** simonw.substack.com
- **Data:** 2024-2025
- **Typ:** Expert practitioner blog
- **Link:** https://simonw.substack.com/p/how-i-use-llms-to-help-me-write-code
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Kluczowy cytat o "slop-recognition function" adjusting. Willison to jeden z najbardziej respektowanych praktyków LLM w community. Pokazuje perspektywę power-usera który dostrzega ograniczenia.

---

### Why Does ChatGPT Use "Delve" So Much?
- **Autor:** Hesam Sheikh
- **Publikacja:** Substack
- **Data:** 2024
- **Typ:** Analysis blog
- **Link:** https://hesamsheikh.substack.com/p/why-does-chatgpt-use-delve-so-much
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Językoznawcza analiza excess vocabulary w AI. Śledzi źródło "delve" do Nigerian English i RLHF annotator demographics. Ciekawy insight do sekcji o homogenizacji stylu.

---

### The Cybernetic Teammate - Ethan Mollick
- **Autor:** Ethan Mollick (Wharton, One Useful Thing)
- **Publikacja:** oneusefulthing.org
- **Data:** 2025
- **Typ:** Expert newsletter
- **Link:** https://www.oneusefulthing.org/p/the-cybernetic-teammate
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Mollick to leading voice na temat AI w pracy. Definiuje Centaur/Cyborg/Self-Automator modes. Cytuje BCG study z 40% quality improvement. Kluczowy dla sekcji o effective collaboration.

---

### Wikipedia: Signs of AI Writing
- **Autor:** Wikipedia community
- **Publikacja:** Wikipedia (meta page)
- **Data:** Ongoing (2024-2025)
- **Typ:** Community-developed detection guide
- **Link:** https://en.wikipedia.org/wiki/Wikipedia:Signs_of_AI_writing
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE-WYSOKIE** - Crowdsourced detection heuristics od edytorów walczących z AI content. Praktyczne przykłady: "rule of three", loss of specificity, exaggeration patterns. Bardzo użyteczne dla sekcji fenomenologia.

---

### Show, Don't Tell: What AI Can't Do - CRAFT Literary
- **Autor:** Laura Hartenberger (UCLA)
- **Publikacja:** CRAFT Literary Magazine
- **Data:** Marzec 2025
- **Typ:** Expert essay
- **Link:** https://www.craftliterary.com/2025/03/26/show-dont-tell-what-ai-cant-do/
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Creative writing instructor perspective. AI "lacks sensory perception to illustrate action of a scene, defaults to summary". Kluczowe dla domain-specific failures w creative writing.

---

### Did Benedict Evans Discover AI is Only Good for 80%-OK Problems?
- **Publikacja:** Innovation Copilots (icopilots.com)
- **Data:** 2025
- **Typ:** Analysis/commentary
- **Link:** https://www.icopilots.com/did-benedict-evans-just-discover-ai-is-only-good-for-solving-80-ok-problems-2/
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **NISKIE-ŚREDNIE** - Secondary commentary on Evans, ale użyteczne framing "80%-OK problems".

---

## 3. QUALITY JOURNALISM I REPORTING

### AI-Generated 'Workslop' Is Destroying Productivity (CNBC)
- **Publikacja:** CNBC
- **Data:** Wrzesień 2025
- **Typ:** Business journalism
- **Link:** https://www.cnbc.com/2025/09/23/ai-generated-workslop-is-destroying-productivity-and-teams-researchers-say.html
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Reporting on Stanford/HBR "workslop" research. 40% employees receive monthly, $186/worker cost. Definiuje termin i problem dla mainstream audience.

---

### AI at Work Is Creating Mountains of Slop (Futurism)
- **Publikacja:** Futurism
- **Data:** 2025
- **Typ:** Tech journalism
- **Link:** https://futurism.com/future-society/ai-productivity-research
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Secondary reporting on Stanford research, ale dobry summary.

---

### ChatGPT's Impact on Our Brains (TIME)
- **Publikacja:** TIME Magazine
- **Data:** 2025
- **Typ:** Mainstream journalism
- **Link:** https://time.com/7295195/ai-chatgpt-google-learning-school/
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE-WYSOKIE** - Reporting on MIT Media Lab EEG study. ChatGPT users showed "lowest brain engagement", essays rated "soulless" by teachers. Accessible presentation of empirical findings.

---

### Deloitte AI Hallucination Reports
- **Publikacje:** Fortune, Entrepreneur, Above the Law, Business Standard
- **Data:** Październik-Listopad 2025
- **Typ:** Business/legal journalism
- **Linki:**
  - https://fortune.com/2025/11/25/deloitte-caught-fabricated-ai-generated-research-million-dollar-report-canada-government/
  - https://fortune.com/2025/10/07/deloitte-ai-australia-government-report-hallucinations-technology-290000-refund/
  - https://www.entrepreneur.com/business-news/deloitte-detected-using-fake-ai-citations-in-1-million/500072
  - https://abovethelaw.com/2025/10/law-professor-catches-deloitte-using-made-up-ai-hallucinations-in-government-report/
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **WYSOKIE** - Real-world case studies: Australia ($290K) and Canada ($1M+) government reports with fabricated citations. Senator Pocock quote: "things a first-year university student would be in deep trouble for". Kluczowe dla consulting domain failures.

---

### OpenAI's Deep Research Agent Is Still Just a Fallible Tool
- **Publikacja:** The Conversation / University of Sydney
- **Data:** Luty 2025
- **Typ:** Academic journalism
- **Link:** https://theconversation.com/openais-new-deep-research-agent-is-still-just-a-fallible-tool-not-a-human-level-expert-249496
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Academic critique of Deep Research claims. Lists systematic failures: lacks context, makes things up, can't distinguish fact from fiction.

---

### AI Hallucinations Strike Again: Lawyers Face Judicial Wrath
- **Publikacja:** LawSites / LawNext
- **Data:** Maj 2025
- **Typ:** Legal industry journalism
- **Link:** https://www.lawnext.com/2025/05/ai-hallucinations-strike-again-two-more-cases-where-lawyers-face-judicial-wrath-for-fake-citations.html
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE-WYSOKIE** - Tracking legal sanctions cases. Part of 823+ global cases database. K&L Gates case where stacking multiple AI tools still produced hallucinations.

---

### AI Hallucination in Legal Cases Remain a Problem
- **Publikacja:** MBHB (law firm analysis)
- **Data:** 2025
- **Typ:** Legal industry analysis
- **Link:** https://www.mbhb.com/intelligence/snippets/ai-hallucination-in-legal-cases-remain-a-problem/
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Practitioner perspective na legal AI failures.

---

### Gemini Deep Research Struggles with Accuracy
- **Publikacja:** The Decoder
- **Data:** 2024
- **Typ:** Tech journalism
- **Link:** https://the-decoder.com/geminis-ai-powered-deep-research-feature-struggles-with-accuracy-in-early-testing/
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Early testing failures of Gemini Deep Research, complement to Evans' OpenAI critique.

---

### Garbage In, Garbage Out: Gemini Deep Research and Humanities
- **Publikacja:** Medium / Age of Awareness
- **Data:** 2025
- **Typ:** Expert essay
- **Link:** https://medium.com/age-of-awareness/garbage-in-garbage-out-why-gemini-deep-research-cant-do-basic-humanities-research-0311c54bdb91
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Humanities professor testing Buddhist studies research. Output "highly partial, biased, anglocentric, uninformed, and generic" - would earn F grade.

---

### 20 Fake Citations Slip Past Peer Review
- **Publikacja:** University Herald
- **Data:** Listopad 2025
- **Typ:** Academic journalism
- **Link:** https://www.universityherald.com/articles/79947/20251110/20-fake-citations-slip-past-peer-review-ai-hallucinations-expose-crisis-academic-publishing.htm
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - University of Hong Kong case: 20/61 references AI-fabricated, passed peer review until social media caught them.

---

### ChatGPT's Hallucination Problem: 56% Fabricated References
- **Publikacja:** Study Finds
- **Data:** 2025
- **Typ:** Science journalism
- **Link:** https://studyfinds.org/chatgpts-hallucination-problem-fabricated-references/
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Reporting on Deakin University study: 1 in 5 citations fabricated, 56% contain errors.

---

### GenAI Is Eroding Critical Thinking (Redmond Mag)
- **Publikacja:** Redmondmag.com
- **Data:** Luty 2025
- **Typ:** Tech journalism
- **Link:** https://redmondmag.com/articles/2025/02/18/genai-is-eroding-critical-thinking.aspx
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **NISKIE-ŚREDNIE** - Secondary reporting on Microsoft Research study.

---

## 4. INDUSTRY ANALYSIS I COMMENTARY

### Stop the Slop - Tim Duggan
- **Autor:** Tim Duggan
- **Publikacja:** Substack
- **Data:** 2025
- **Typ:** Newsletter/essay
- **Link:** https://timduggan.substack.com/p/stop-the-slop
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **NISKIE-ŚREDNIE** - General commentary on AI slop phenomenon.

---

### In a "Sea of Sameness," Taste and Storytelling Will Become Vital
- **Publikacja:** It's Nice That
- **Data:** Lipiec 2024
- **Typ:** Creative industry journalism
- **Link:** https://www.itsnicethat.com/articles/pov-will-ai-turn-human-creativity-into-a-luxury-good-creative-industry-310724
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Creative industry perspective on taste as emerging skill. "Sea of sameness" framing.

---

### AI and the Future of Work: Centaurs and Cyborgs
- **Publikacja:** Siili (consulting firm)
- **Data:** 2024-2025
- **Typ:** Industry analysis
- **Link:** https://www.siili.com/stories/ai-future-of-work-centaurs-and-cyborgs
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Explains Centaur/Cyborg framework from BCG/Harvard research.

---

### The Idea of "AI Slop" Is Slop - Philosophical Salon
- **Publikacja:** The Philosophical Salon
- **Data:** 2025
- **Typ:** Philosophy essay
- **Link:** https://www.thephilosophicalsalon.com/the-idea-of-ai-slop-is-slop/
- **Autorytatywność:** ⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Counterargument perspective. Sturgeon's Law framing: mediocrity predates AI.

---

### Mapping the Limitations of Current AI Systems (UK AISI)
- **Publikacja:** UK AI Safety Institute
- **Data:** 2024-2025
- **Typ:** Government research
- **Link:** https://www.aisi.gov.uk/blog/mapping-the-limitations-of-current-ai-systems
- **Autorytatywność:** ⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Official UK government assessment of AI limitations.

---

### AI, Knowledge Synthesis, and Philosophy of Science (Springer)
- **Publikacja:** Springer Nature Link
- **Data:** 2025
- **Typ:** Academic collection
- **Link:** https://link.springer.com/collections/haijbhbjhi
- **Autorytatywność:** ⭐⭐⭐⭐⭐
- **Znaczenie dla researchu:** **ŚREDNIE** - Special issue on AI limitations in knowledge synthesis. Quote: "LLMs operate through probabilistic pattern recognition... outputs reflect statistically likely continuations rather than engagement with evidence."

---

### Mathematical Ceiling Article (Modern Engineering Marvels)
- **Publikacja:** Modern Engineering Marvels
- **Data:** Listopad 2025
- **Typ:** Secondary reporting
- **Link:** https://modernengineeringmarvels.com/2025/11/27/mathematical-ceiling-reveals-why-ai-stalls-at-amateur-creativity/
- **Autorytatywność:** ⭐⭐
- **Znaczenie dla researchu:** **NISKIE** - Secondary coverage of Cropley research.

---

### Model Collapse and Data Crisis
- **Publikacja:** Soft4led
- **Data:** 2025
- **Typ:** Tech blog
- **Link:** https://www.soft4led.com/the-ai-data-crisis-why-fresh-web-scraping-is-the-only-cure-for-model-collapse/
- **Autorytatywność:** ⭐⭐
- **Znaczenie dla researchu:** **NISKIE** - Discussion of model collapse from training on AI content.

---

## 5. PODSUMOWANIE WEDŁUG KATEGORII

### Najważniejsze źródła (must-read):
1. **Cropley (2025)** - Mathematical ceiling proof
2. **Peng et al. (2024)** - Transformer architecture limitations
3. **MDPI/SBS (2025)** - Empirical critical thinking study (n=666)
4. **Benedict Evans (2025)** - Deep Research critique
5. **Stanford HAI (2024)** - Legal hallucination benchmark
6. **Georgetown/Stanford (2024)** - Homogenization study

### Najlepsze case studies:
1. **Deloitte Australia/Canada** - Consulting failures
2. **K&L Gates** - Legal multi-tool failures
3. **University of Hong Kong** - Peer review failures

### Dla teorii i mechanizmów:
1. **LLM Cannot Discover Causality**
2. **UW RLHF Research**
3. **Apple Illusion of Thinking**

### Dla kontrargumentów:
1. **Mollick/BCG studies** - 40% quality improvement
2. **Philosophical Salon** - "AI Slop Is Slop"
3. **Siili Centaurs/Cyborgs** - Effective collaboration modes

---

## 6. DO DALSZEJ EKSPLORACJI (paywall lub wymaga głębszego czytania)

- **Original Cropley paper** w Journal of Creative Behavior (full methodology)
- **BCG/Harvard "Jagged Frontier" study** (original, not summaries)
- **Microsoft Research full report** on critical thinking
- **LAMP Corpus study** (creative writing analysis across models)
- **Damien Charlotin's database** of 823+ legal hallucination cases

---

*Wygenerowano: Styczeń 2025*
*Liczba źródeł: 45+*
*Zakres dat publikacji: 2023-2025*
